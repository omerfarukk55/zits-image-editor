import os
import base64
import io
import uuid
from flask import Flask, render_template, request, redirect, url_for, jsonify, send_from_directory
from werkzeug.utils import secure_filename
from PIL import Image
import traceback
import cv2
import numpy as np
from io import BytesIO
from models.zits_model import ZITSInpainter
from models.background_remover import BackgroundRemover
from moviepy.editor import VideoFileClip, ImageSequenceClip
from models.raft.raft_wrapper import RAFTOpticalFlow
import torch
import torchvision.transforms as transforms  # Bu satƒ±rƒ± ekleyin
from models.raft.raft import RAFT
import argparse
from datetime import datetime
import time
try:
    from scipy import ndimage
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    print("Scipy mevcut deƒüil, OpenCV blur kullanƒ±lacak")

app = Flask(__name__, static_folder='static')
app.config['UPLOAD_FOLDER'] = os.path.join('static', 'uploads')
app.config['PROCESSED_FOLDER'] = os.path.join('static', 'processed')
app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg'}
app.config['ALLOWED_VIDEO_EXTENSIONS'] = {'mp4', 'avi', 'mov', 'mkv'}

# Upload klas√∂rlerini olu≈ütur
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['PROCESSED_FOLDER'], exist_ok=True)
os.makedirs('temp', exist_ok=True)
os.makedirs('static/results', exist_ok=True)

# Modelleri ba≈ülat
try:
    print("ZITS modeli ba≈ülatƒ±lƒ±yor...")
    zits_model = ZITSInpainter()
    print("ZITS modeli ba≈üarƒ±yla ba≈ülatƒ±ldƒ±")
except Exception as e:
    print(f"ZITS modeli ba≈ülatma hatasƒ±: {e}")
    zits_model = None

try:
    print("Arka plan kaldƒ±rma modeli ba≈ülatƒ±lƒ±yor...")
    background_remover = BackgroundRemover()
    print("Arka plan kaldƒ±rma modeli ba≈üarƒ±yla ba≈ülatƒ±ldƒ±")
except Exception as e:
    print(f"Arka plan kaldƒ±rma modeli ba≈ülatma hatasƒ±: {e}")
    background_remover = None

# Global deƒüi≈ükenler
raft_model = None

def load_raft_model():
    try:
        print("RAFT modeli y√ºkleniyor...")
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"RAFT modeli i√ßin kullanƒ±lacak cihaz: {device}")
        
        # RAFT model yapƒ±landƒ±rmasƒ±
        args_dict = {
            'model': 'raft-things.pth',
            'small': False,
            'mixed_precision': True,
            'hidden_dims': [128]*3,
            'context_dims': [128]*3,
            'corr_implementation': 'reg',
            'corr_levels': 4,
            'corr_radius': 4,
            'mask_pred': False,
            'dropout': 0.0,
            'alternate_corr': False,
            'mask_pred_hidden_dims': [128]*3,
            'mask_pred_context_dims': [128]*3,
            'mask_pred_corr_levels': 4,
            'mask_pred_corr_radius': 4
        }
        
        args = argparse.Namespace(**args_dict)
        
        # Model dosyasƒ±nƒ±n varlƒ±ƒüƒ±nƒ± kontrol et
        model_path = os.path.join('models/raft', args.model)
        if not os.path.exists(model_path):
            print(f"HATA: Model dosyasƒ± bulunamadƒ±: {model_path}")
            return None
            
        print(f"Model dosyasƒ± bulundu: {model_path}")
        
        model = RAFT(args)
        state_dict = torch.load(model_path, map_location=device)
        
        # DataParallel prefix'ini temizle
        if list(state_dict.keys())[0].startswith('module.'):
            new_state_dict = {}
            for key, value in state_dict.items():
                new_key = key.replace('module.', '')
                new_state_dict[new_key] = value
            state_dict = new_state_dict
        
        model.load_state_dict(state_dict)
        model.to(device)
        model.eval()
        
        print("RAFT modeli ba≈üarƒ±yla y√ºklendi.")
        return model
        
    except Exception as e:
        print(f"RAFT modeli y√ºklenirken hata: {str(e)}")
        print("Hata detayƒ±:", traceback.format_exc())
        return None

# RAFT modelini ba≈ülat
try:
    raft_model = load_raft_model()
except Exception as e:
    print(f"RAFT model ba≈ülatma hatasƒ±: {e}")
    raft_model = None

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

def allowed_video_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_VIDEO_EXTENSIONS']

def frame_to_tensor(frame, device):
    """OpenCV frame'i RAFT i√ßin tensor'e √ßevir"""
    try:
        # BGR -> RGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # PIL Image -> Tensor
        pil_image = Image.fromarray(frame_rgb)
        
        transform = transforms.Compose([
            transforms.ToTensor(),
        ])
        
        tensor = transform(pil_image)
        tensor = tensor.unsqueeze(0)  # Batch dimension
        tensor = tensor.to(device)
        tensor = tensor * 255.0  # RAFT 0-255 bekliyor
        
        return tensor
        
    except Exception as e:
        print(f"Frame tensor √ßevirme hatasƒ±: {e}")
        return None

def tensor_to_flow(tensor):
    """RAFT tensor √ßƒ±ktƒ±sƒ±nƒ± flow array'e √ßevir"""
    try:
        if tensor.is_cuda:
            tensor = tensor.cpu()
        
        flow = tensor.detach().numpy()
        
        # [1, 2, H, W] -> [H, W, 2]
        if flow.ndim == 4 and flow.shape[0] == 1:
            flow = flow.squeeze(0)
        
        if flow.shape[0] == 2:
            flow = flow.transpose(1, 2, 0)
        
        return flow
        
    except Exception as e:
        print(f"Tensor flow √ßevirme hatasƒ±: {e}")
        return None

def apply_flow_to_mask(mask, flow):
    """Optik akƒ±≈üƒ± kullanarak maskeyi hareket ettirir."""
    try:
        h, w = mask.shape[:2]
        y, x = np.mgrid[0:h, 0:w].astype(np.float32)
        
        flow_x = flow[..., 0]
        flow_y = flow[..., 1]
        new_x = x + flow_x
        new_y = y + flow_y
        
        new_x = np.clip(new_x, 0, w-1)
        new_y = np.clip(new_y, 0, h-1)
        
        new_mask = cv2.remap(mask, new_x, new_y, cv2.INTER_LINEAR)
        
        return new_mask
    except Exception as e:
        print(f"Maske hareket ettirme hatasƒ±: {str(e)}")
        return mask

def apply_mask_to_frame(frame, mask):
    """Mask'ƒ± frame'e uygula"""
    try:
        # Mask'ƒ±n 3 kanallƒ± olduƒüundan emin ol
        if len(mask.shape) == 2:
            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        elif mask.shape[2] == 4:  # RGBA
            mask = cv2.cvtColor(mask, cv2.COLOR_RGBA2BGR)
        
        # Frame boyutuna uygun hale getir
        if mask.shape[:2] != frame.shape[:2]:
            mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]))
        
        # Alpha blending
        alpha = 0.7
        
        # Mask'ƒ±n siyah olmayan kƒ±sƒ±mlarƒ±nƒ± bul
        mask_binary = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
        mask_binary = (mask_binary > 10).astype(np.uint8) * 255
        
        # 3 kanala √ßevir
        mask_3ch = cv2.merge([mask_binary, mask_binary, mask_binary]) / 255.0
        
        # Blending uygula
        result = frame.astype(np.float32)
        mask_colored = mask.astype(np.float32)
        
        result = result * (1 - mask_3ch * alpha) + mask_colored * mask_3ch * alpha
        
        return result.astype(np.uint8)
        
    except Exception as e:
        print(f"Mask uygulama hatasƒ±: {e}")
        return frame

def apply_flow_to_mask_improved(mask, flow, max_flow_magnitude=30, smooth_factor=0.7):
    """D√ºzeltilmi≈ü geli≈ümi≈ü mask hareket ettirme"""
    try:
        h, w = mask.shape[:2]
        
        # 1. Flow magnitude kontrol√º
        flow_magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)
        valid_flow_mask = flow_magnitude < max_flow_magnitude
        
        # 2. Outlier'larƒ± temizle
        flow_filtered = flow.copy()
        flow_filtered[~valid_flow_mask] = 0
        
        # 3. Flow'u smooth et - Scipy kontrol√º
        if SCIPY_AVAILABLE:
            try:
                flow_filtered[..., 0] = ndimage.gaussian_filter(flow_filtered[..., 0], sigma=1.0)
                flow_filtered[..., 1] = ndimage.gaussian_filter(flow_filtered[..., 1], sigma=1.0)
            except:
                # Scipy hatasƒ± durumunda OpenCV kullan
                flow_filtered[..., 0] = cv2.GaussianBlur(flow_filtered[..., 0], (5, 5), 1.0)
                flow_filtered[..., 1] = cv2.GaussianBlur(flow_filtered[..., 1], (5, 5), 1.0)
        else:
            # Scipy yoksa OpenCV blur kullan
            flow_filtered[..., 0] = cv2.GaussianBlur(flow_filtered[..., 0], (5, 5), 1.0)
            flow_filtered[..., 1] = cv2.GaussianBlur(flow_filtered[..., 1], (5, 5), 1.0)
        
        # 4. Mask'ƒ± grayscale'e √ßevir
        if len(mask.shape) == 3:
            mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
        else:
            mask_gray = mask
        
        # 5. Aktif b√∂lgeleri bul
        active_mask = mask_gray > 10
        
        if not np.any(active_mask):
            return mask
        
        # 6. Aktif b√∂lgedeki flow'u hesapla
        active_indices = np.where(active_mask)
        if len(active_indices[0]) == 0:
            return mask
        
        active_flow_x = flow_filtered[active_indices[0], active_indices[1], 0]
        active_flow_y = flow_filtered[active_indices[0], active_indices[1], 1]
        
        # 7. Median flow hesapla (robust)
        median_flow_x = np.median(active_flow_x)
        median_flow_y = np.median(active_flow_y)
        
        # 8. Flow'u sƒ±nƒ±rla ve yumu≈üat
        median_flow_x = np.clip(median_flow_x, -max_flow_magnitude, max_flow_magnitude) * smooth_factor
        median_flow_y = np.clip(median_flow_y, -max_flow_magnitude, max_flow_magnitude) * smooth_factor
        
        # 9. Koordinat gridleri
        y_coords, x_coords = np.mgrid[0:h, 0:w].astype(np.float32)
        
        # 10. Yeni koordinatlar
        new_x = x_coords + median_flow_x
        new_y = y_coords + median_flow_y
        
        # 11. Sƒ±nƒ±rlarƒ± kontrol et
        new_x = np.clip(new_x, 0, w-1)
        new_y = np.clip(new_y, 0, h-1)
        
        # 12. Mask'ƒ± hareket ettir
        new_mask = cv2.remap(mask, new_x, new_y, cv2.INTER_LINEAR)
        
        return new_mask
        
    except Exception as e:
        print(f"Geli≈ümi≈ü mask hareket ettirme hatasƒ±: {e}")
        return mask
def calculate_temporal_consistency_fixed(previous_masks, weight_decay=0.8):
    """D√ºzeltilmi≈ü temporal tutarlƒ±lƒ±k"""
    try:
        if len(previous_masks) == 0:
            return None
        
        # ƒ∞lk mask'ƒ±n boyutlarƒ±nƒ± referans al
        reference_mask = previous_masks[-1]
        
        # Referans mask'ƒ± grayscale'e √ßevir ve boyutlarƒ± al
        if len(reference_mask.shape) == 3:
            reference_gray = cv2.cvtColor(reference_mask, cv2.COLOR_BGR2GRAY)
            h, w = reference_gray.shape
        else:
            reference_gray = reference_mask
            h, w = reference_mask.shape
        
        # Birle≈ütirme i√ßin grayscale array olu≈ütur
        combined_mask = np.zeros((h, w), dtype=np.float32)
        total_weight = 0
        
        # Son 5 mask'ƒ± i≈üle
        for i, mask in enumerate(reversed(previous_masks[-5:])):
            weight = weight_decay ** i
            
            # Mask'ƒ± grayscale'e √ßevir
            if len(mask.shape) == 3:
                mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
            else:
                mask_gray = mask.copy()
            
            # Boyut uyumluluƒüunu kontrol et ve d√ºzelt
            if mask_gray.shape != (h, w):
                mask_gray = cv2.resize(mask_gray, (w, h))
            
            # Aƒüƒ±rlƒ±klƒ± toplama
            combined_mask += mask_gray.astype(np.float32) * weight
            total_weight += weight
        
        # Normaliz et
        if total_weight > 0:
            combined_mask /= total_weight
        
        # Threshold uygula ve uint8'e √ßevir
        combined_mask = (combined_mask > 50).astype(np.uint8) * 255
        
        return combined_mask
        
    except Exception as e:
        print(f"Temporal consistency hatasƒ±: {e}")
        return None

def process_video_with_improved_tracking(video_path, mask_image):
    """D√ºzeltilmi≈ü geli≈ümi≈ü optical flow takibi"""
    try:
        print("üéØ D√ºzeltilmi≈ü RAFT Optical Flow takibi ba≈ülatƒ±lƒ±yor...")
        
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise Exception("Video dosyasƒ± a√ßƒ±lamadƒ±")
        
        # Video bilgileri
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"üìπ Video: {width}x{height}, {fps}fps, {total_frames} frame")
        
        # √áƒ±ktƒ± dosyasƒ±
        timestamp = str(int(time.time()))
        output_path = os.path.join('static/results', f'fixed_tracking_{timestamp}.mp4')
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # Video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        if not out.isOpened():
            raise Exception("Video writer a√ßƒ±lamadƒ±")
        
        # Mask'ƒ± hazƒ±rla - boyut standartla≈ütƒ±rmasƒ±
        print(f"üé® Orijinal mask shape: {mask_image.shape}")
        
        if len(mask_image.shape) == 3 and mask_image.shape[2] == 4:  # RGBA
            mask_resized = cv2.resize(mask_image, (width, height))
            mask_resized = cv2.cvtColor(mask_resized, cv2.COLOR_RGBA2BGR)
        elif len(mask_image.shape) == 3:  # RGB/BGR
            mask_resized = cv2.resize(mask_image, (width, height))
        else:  # Grayscale
            mask_resized = cv2.resize(mask_image, (width, height))
            mask_resized = cv2.cvtColor(mask_resized, cv2.COLOR_GRAY2BGR)
        
        print(f"üé® Yeniden boyutlandƒ±rƒ±lmƒ±≈ü mask: {mask_resized.shape}")
        
        # ƒ∞lk frame'i oku
        ret, prev_frame = cap.read()
        if not ret:
            raise Exception("ƒ∞lk frame okunamadƒ±")
        
        # Deƒüi≈ükenler
        current_mask = mask_resized.copy()
        mask_history = []
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ƒ∞lk frame'i i≈üle
        first_frame_result = apply_mask_to_frame(prev_frame, current_mask)
        out.write(first_frame_result)
        mask_history.append(current_mask.copy())
        
        frame_count = 1
        
        # RAFT modeli kontrol√º
        if raft_model is None:
            print("‚ö†Ô∏è RAFT modeli yok, basit i≈üleme uygulanƒ±yor...")
            return process_video_simple_drawing(cap, out, mask_resized, total_frames, output_path)
        
        while True:
            ret, current_frame = cap.read()
            if not ret:
                break
                
            frame_count += 1
            
            # Progress
            if frame_count % 30 == 0:
                print(f"üìä ƒ∞≈üleniyor: {frame_count}/{total_frames}")
            
            try:
                # RAFT ile optical flow hesapla
                prev_tensor = frame_to_tensor(prev_frame, device)
                curr_tensor = frame_to_tensor(current_frame, device)
                
                if prev_tensor is not None and curr_tensor is not None:
                    with torch.no_grad():
                        _, flow_tensor = raft_model(prev_tensor, curr_tensor, iters=12, test_mode=True)
                    
                    flow = tensor_to_flow(flow_tensor)
                    
                    if flow is not None:
                        # Flow'u mask boyutuna √∂l√ßekle
                        if flow.shape[:2] != current_mask.shape[:2]:
                            flow_resized = cv2.resize(flow, (current_mask.shape[1], current_mask.shape[0]))
                        else:
                            flow_resized = flow
                        
                        # D√ºzeltilmi≈ü mask hareket ettirme
                        current_mask = apply_flow_to_mask_improved(
                            current_mask, 
                            flow_resized, 
                            max_flow_magnitude=25,  # Daha konservatif
                            smooth_factor=0.8       # Daha smooth
                        )
                        
                        # Temporal tutarlƒ±lƒ±k (d√ºzeltilmi≈ü)
                        if len(mask_history) > 2:
                            temporal_mask = calculate_temporal_consistency_fixed(mask_history[-3:])
                            if temporal_mask is not None:
                                # Mevcut mask'ƒ± grayscale'e √ßevir
                                if len(current_mask.shape) == 3:
                                    current_mask_gray = cv2.cvtColor(current_mask, cv2.COLOR_BGR2GRAY)
                                else:
                                    current_mask_gray = current_mask.copy()
                                
                                # Boyut kontrol√º
                                if temporal_mask.shape != current_mask_gray.shape:
                                    temporal_mask = cv2.resize(temporal_mask, 
                                                             (current_mask_gray.shape[1], current_mask_gray.shape[0]))
                                
                                # Aƒüƒ±rlƒ±klƒ± birle≈ütirme
                                alpha = 0.6
                                combined = (current_mask_gray.astype(np.float32) * alpha + 
                                          temporal_mask.astype(np.float32) * (1-alpha)).astype(np.uint8)
                                
                                # Geri BGR'e √ßevir
                                if len(current_mask.shape) == 3:
                                    current_mask = cv2.cvtColor(combined, cv2.COLOR_GRAY2BGR)
                                else:
                                    current_mask = combined
                        
                        # Mask ge√ßmi≈üini g√ºncelle
                        mask_history.append(current_mask.copy())
                        if len(mask_history) > 5:  # Sadece son 5 mask
                            mask_history.pop(0)
                    
                    else:
                        print(f"‚ö†Ô∏è Frame {frame_count}: Flow hesaplanamadƒ±")
                else:
                    print(f"‚ö†Ô∏è Frame {frame_count}: Tensor √ßevrimi ba≈üarƒ±sƒ±z")
                
                # Frame'i i≈üle
                frame_result = apply_mask_to_frame(current_frame, current_mask)
                out.write(frame_result)
                
                # Bir sonraki iterasyon i√ßin
                prev_frame = current_frame.copy()
                
            except Exception as frame_error:
                print(f"‚ùå Frame {frame_count} hatasƒ±: {frame_error}")
                # Hata durumunda √∂nceki mask'ƒ± kullan
                frame_result = apply_mask_to_frame(current_frame, current_mask)
                out.write(frame_result)
        
        cap.release()
        out.release()
        
        print(f"‚úÖ D√ºzeltilmi≈ü takip tamamlandƒ±: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"‚ùå D√ºzeltilmi≈ü takip hatasƒ±: {str(e)}")
        print("Detay:", traceback.format_exc())
        return None

def process_video_simple_drawing(cap, out, mask, total_frames, output_path):
    """RAFT olmadan basit √ßizim uygulama"""
    try:
        print("Basit √ßizim uygulanƒ±yor...")
        
        frame_count = 1
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            frame_count += 1
            
            if frame_count % 50 == 0:
                print(f"Basit frame i≈üleniyor: {frame_count}/{total_frames}")
            
            frame_with_drawing = apply_mask_to_frame(frame, mask)
            out.write(frame_with_drawing)
        
        cap.release()
        out.release()
        
        print(f"Basit video i≈üleme tamamlandƒ±: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"Basit √ßizim hatasƒ±: {e}")
        if cap:
            cap.release()
        if out:
            out.release()
        return None

# Flask Routes
@app.route('/')
def home():
    return render_template('home.html')

@app.route('/editor')
def editor():
    try:
        file_url = request.args.get('file_url', '')
        return render_template('editor.html', file_url=file_url)
    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/remove-bg')
def remove_bg_page():
    try:
        return render_template('remove_bg.html')
    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/upload', methods=['POST'])
def upload_file():
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'Dosya y√ºklenmedi'})
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'success': False, 'error': 'Dosya se√ßilmedi'})
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            
            file.save(file_path)
            
            return jsonify({
                'success': True,
                'filename': filename,
                'file_url': url_for('static', filename=f"uploads/{filename}")
            })
        
        return jsonify({'success': False, 'error': 'ƒ∞zin verilmeyen dosya t√ºr√º'})
    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})

@app.route('/download/<filename>')
def download_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename, as_attachment=True)

@app.route('/process_image', methods=['POST'])
def process_image():
    try:
        filename = request.form.get('filename')
        mask_data = request.form.get('mask')
        
        if not filename or not mask_data:
            return jsonify({'success': False, 'error': 'Eksik veri'}), 400
        
        img_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        if not os.path.exists(img_path):
            return jsonify({'success': False, 'error': 'Dosya bulunamadƒ±'}), 404
        
        image = cv2.imread(img_path)
        if image is None:
            return jsonify({'success': False, 'error': 'G√∂r√ºnt√º okunamadƒ±'}), 400
        
        try:
            mask_data = mask_data.split(',')[1]
            mask_bytes = base64.b64decode(mask_data)
            mask_arr = np.frombuffer(mask_bytes, np.uint8)
            mask = cv2.imdecode(mask_arr, cv2.IMREAD_GRAYSCALE)
            
            mask = cv2.resize(mask, (image.shape[1], image.shape[0]))
            
            result = zits_model.inpaint(image, mask)
            
            output_filename = f"processed_{uuid.uuid4().hex}.png"
            output_path = os.path.join(app.config['PROCESSED_FOLDER'], output_filename)
            cv2.imwrite(output_path, result)
            
            return jsonify({
                'success': True,
                'processed_image': url_for('static', filename=f'processed/{output_filename}')
            })
            
        except Exception as e:
            print(f"Hata: {str(e)}")
            return jsonify({'success': False, 'error': str(e)}), 500
            
    except Exception as e:
        print(f"Genel hata: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/remove_background', methods=['POST'])
def remove_background():
    try:
        filename = request.form.get('filename')
        bg_color = request.form.get('bg_color', 'transparent')
        
        if not filename:
            return jsonify({'success': False, 'error': 'Dosya adƒ± belirtilmedi'}), 400
        
        img_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        if not os.path.exists(img_path):
            return jsonify({'success': False, 'error': 'Dosya bulunamadƒ±'}), 404
        
        image = cv2.imread(img_path)
        if image is None:
            return jsonify({'success': False, 'error': 'G√∂r√ºnt√º okunamadƒ±'}), 400
        
        try:
            result = background_remover.remove_background(image)
            
            if bg_color != 'transparent':
                from PIL import ImageColor
                rgb_color = ImageColor.getrgb(bg_color)
                pil_img = Image.fromarray(result)
                background = Image.new('RGBA', pil_img.size, rgb_color + (255,))
                background.paste(pil_img, mask=pil_img.split()[3])
                result = np.array(background.convert('RGB'))
                save_mode = 'JPEG'
                output_ext = 'jpg'
            else:
                save_mode = 'PNG'
                output_ext = 'png'
            
            output_filename = f"nobg_{uuid.uuid4().hex}.{output_ext}"
            output_path = os.path.join(app.config['PROCESSED_FOLDER'], output_filename)
            Image.fromarray(result).save(output_path, save_mode)
            
            return jsonify({
                'success': True,
                'processed_image': url_for('static', filename=f'processed/{output_filename}')
            })
            
        except Exception as e:
            print(f"Hata: {str(e)}")
            return jsonify({'success': False, 'error': str(e)}), 500
            
    except Exception as e:
        print(f"Genel hata: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/img-draw-editor')
def img_draw_editor():
    return render_template('imgdraw_editor.html')

@app.route('/vid-draw-editor')
def vid_draw_editor():
    return render_template('viddraw_editor.html')

@app.route('/draw_process_image', methods=['POST'])
def draw_process_image():
    try:
        if 'original_file' not in request.files or 'draw_data_url' not in request.form:
            return jsonify({'success': False, 'error': 'Dosya veya √ßizim verisi eksik'}), 400
        
        original_file = request.files['original_file']
        draw_data_url = request.form['draw_data_url']
        
        if original_file.filename == '':
            return jsonify({'success': False, 'error': 'Dosya se√ßilmedi'}), 400
        
        if '.' not in original_file.filename or original_file.filename.rsplit('.', 1)[1].lower() not in app.config['ALLOWED_EXTENSIONS']:
            return jsonify({'success': False, 'error': 'Desteklenmeyen dosya formatƒ±'}), 400
        
        filename = secure_filename(original_file.filename)
        unique_filename = f"{uuid.uuid4().hex}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        original_file.save(filepath)
        
        try:
            draw_data_header, draw_data_base64 = draw_data_url.split(',', 1)
            draw_bytes = base64.b64decode(draw_data_base64)
            draw_img = Image.open(io.BytesIO(draw_bytes)).convert('RGBA')
        except Exception as e:
            if os.path.exists(filepath):
                os.remove(filepath)
            return jsonify({'success': False, 'error': f'√áizim verisi i≈ülenirken hata: {str(e)}'}), 400

        try:
            img = Image.open(filepath).convert('RGBA')
        except Exception as e:
            if os.path.exists(filepath):
                os.remove(filepath)
            return jsonify({'success': False, 'error': f'Orijinal g√∂rsel a√ßƒ±lƒ±rken hata: {str(e)}'}), 400
        
        if draw_img.size != img.size:
            draw_img = draw_img.resize(img.size, Image.Resampling.LANCZOS)
        result = Image.alpha_composite(img, draw_img)
        
        result_filename = 'processed_' + unique_filename
        result_path = os.path.join(app.config['PROCESSED_FOLDER'], result_filename)
        
        result.save(result_path, 'PNG')
        
        if os.path.exists(filepath):
            os.remove(filepath)
        
        return jsonify({
            'success': True,
            'result_url': url_for('static', filename=f'processed/{result_filename}')
        })
        
    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'Sunucu hatasƒ±: {str(e)}'}), 500

@app.route('/draw_process_video', methods=['POST'])
def draw_process_video():
    """Geli≈ümi≈ü nesne takipli video i≈üleme"""
    try:
        print("üé¨ Video i≈üleme isteƒüi alƒ±ndƒ±")
        
        video_file = request.files.get('video_file')
        draw_mask_url = request.form.get('draw_mask_url')
        
        if not video_file or not draw_mask_url:
            return jsonify({'success': False, 'error': 'Video dosyasƒ± ve √ßizim maskesi gerekli'})
        
        # Ge√ßici dosya olu≈ütur
        temp_video_path = os.path.join('temp', secure_filename(video_file.filename))
        os.makedirs('temp', exist_ok=True)
        video_file.save(temp_video_path)
        print(f"üìÅ Video ge√ßici olarak kaydedildi: {temp_video_path}")
        
        # Mask'ƒ± decode et
        try:
            mask_data = draw_mask_url.split(',')[1]
            mask_bytes = base64.b64decode(mask_data)
            mask_image = Image.open(io.BytesIO(mask_bytes))
            mask_array = np.array(mask_image)
            print(f"üé® Mask i≈ülendi: {mask_array.shape}")
        except Exception as mask_error:
            return jsonify({'success': False, 'error': f'Mask i≈üleme hatasƒ±: {str(mask_error)}'})
        
        # Geli≈ümi≈ü optical flow takipli video i≈üle
        result_path = process_video_with_improved_tracking(temp_video_path, mask_array)
        # Ge√ßici dosyayƒ± temizle
        try:
            os.remove(temp_video_path)
            print("üóëÔ∏è Ge√ßici dosya silindi")
        except:
            pass
        
        if result_path and os.path.exists(result_path):
            print(f"‚úÖ Video i≈üleme ba≈üarƒ±yla tamamlandƒ±: {result_path}")
            return jsonify({
                'success': True, 
                'result_url': '/' + result_path.replace('\\', '/')
            })
        else:
            print("‚ùå Video i≈üleme ba≈üarƒ±sƒ±z")
            return jsonify({'success': False, 'error': 'Video i≈üleme ba≈üarƒ±sƒ±z'})
            
    except Exception as e:
        print(f"‚ùå Video i≈ülenirken hata olu≈ütu: {str(e)}")
        print("Detay:", traceback.format_exc())
        return jsonify({'success': False, 'error': str(e)})

if __name__ == '__main__':
    app.run(debug=True)